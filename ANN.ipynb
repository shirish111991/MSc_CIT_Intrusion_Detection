{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NWc0PXoU4K1"
   },
   "source": [
    "# Artificial Neural Networks with the help of Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.tensorflow.org/tutorials/keras/classification\">Tensor Flow Documentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"\"\"<a href=\"https://www.tensorflow.org/tutorials/keras/classification\">Tensor Flow Documentation</a>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow ANN\n",
    "# https://www.tensorflow.org/tutorials/keras/classification\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# Defing F1 function as new documentation doesn't have function to predict F1-Matric.\n",
    "# Calculate Recall\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "# Calculating Precision for F1-Score\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    \n",
    "# Calculating F1 by putting recall and precision in the formulae\n",
    "# Epsilon is an arbitrary smaller value used to avoid devide by 0 error.\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46r2j8t2YmKC"
   },
   "outputs": [],
   "source": [
    "# Loading data from test and train files from google drive\n",
    "from joblib import load\n",
    "X_tr=load(\"/content/drive/My Drive/Data set/X_tr.joblib\")\n",
    "X_test=load(\"/content/drive/My Drive/Data set/X_test.joblib\")\n",
    "y_tr=load(\"/content/drive/My Drive/Data set/y_tr.joblib\")\n",
    "y_test=load(\"/content/drive/My Drive/Data set/y_test.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "2Htt3Bw8Y2Vr",
    "outputId": "b7780e2b-a8d5-4482-a333-25b469d1416a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 122) (125973,) (22544, 122) (22544,)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape,y_tr.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "colab_type": "code",
    "id": "e3zYCrFbY79u",
    "outputId": "b48cbb5f-6356-4dae-c1cc-b648919145c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.16.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.6/dist-packages (from optuna) (4.2.1)\n",
      "Requirement already satisfied: cmaes>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from optuna) (0.6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from optuna) (20.4)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.18)\n",
      "Requirement already satisfied: cliff in /usr/local/lib/python3.6/dist-packages (from optuna) (3.3.0)\n",
      "Requirement already satisfied: alembic in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->optuna) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->optuna) (2.4.7)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (5.4.5)\n",
      "Requirement already satisfied: stevedore>=1.20.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.2.0)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
      "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
      "Requirement already satisfied: cmd2!=0.8.3,>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.2.1)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (1.1.3)\n",
      "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (1.0.4)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.7.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from stevedore>=1.20.0->cliff->optuna) (1.7.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.4.3)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (19.3.0)\n",
      "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (49.2.0)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=1.20.0->cliff->optuna) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "XBBOsIxdZg4i",
    "outputId": "c33aece5-8d99-4d54-ff7d-5e016542de00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 5) (22544, 5)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# converting class labels to one hot encoded features\n",
    "y_tr=np_utils.to_categorical(y_tr)\n",
    "y_test=np_utils.to_categorical(y_test)\n",
    "print(y_tr.shape,y_test.shape)\n",
    "\n",
    "# Getting the input and output from the data set.\n",
    "input_dimensions=X_tr.shape[1]\n",
    "output_dimension=y_tr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://optuna.org/#code_examples\">Optuna</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"\"\"<a href=\"https://optuna.org/#code_examples\">Optuna</a>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "pjWC0P-oaEwk",
    "outputId": "c155b6c0-9451-418c-8ecd-ef3d69d447a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-03 01:26:25,715] Using an existing study with name 'NN_tuning' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.032642182568550754 tanh\n",
      "Epoch 1/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.2279 - f1: 0.9272 - accuracy: 0.9305 - val_loss: 1.4800 - val_f1: 0.7285 - val_accuracy: 0.7278\n",
      "Epoch 2/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.1186 - f1: 0.9623 - accuracy: 0.9625 - val_loss: 1.4823 - val_f1: 0.7177 - val_accuracy: 0.7174\n",
      "Epoch 3/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.1141 - f1: 0.9603 - accuracy: 0.9604 - val_loss: 1.5047 - val_f1: 0.7202 - val_accuracy: 0.7157\n",
      "Epoch 4/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0995 - f1: 0.9627 - accuracy: 0.9627 - val_loss: 1.4151 - val_f1: 0.7299 - val_accuracy: 0.7301\n",
      "Epoch 5/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.1011 - f1: 0.9651 - accuracy: 0.9651 - val_loss: 1.4964 - val_f1: 0.7406 - val_accuracy: 0.7402\n",
      "Epoch 6/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0962 - f1: 0.9677 - accuracy: 0.9676 - val_loss: 1.4341 - val_f1: 0.7234 - val_accuracy: 0.7230\n",
      "Epoch 7/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0910 - f1: 0.9677 - accuracy: 0.9677 - val_loss: 1.5528 - val_f1: 0.7406 - val_accuracy: 0.7399\n",
      "Epoch 8/15\n",
      "985/985 [==============================] - 8s 9ms/step - loss: 0.0868 - f1: 0.9681 - accuracy: 0.9682 - val_loss: 1.4591 - val_f1: 0.7209 - val_accuracy: 0.7207\n",
      "Epoch 9/15\n",
      "985/985 [==============================] - 9s 9ms/step - loss: 0.0809 - f1: 0.9685 - accuracy: 0.9684 - val_loss: 1.5782 - val_f1: 0.7510 - val_accuracy: 0.7504\n",
      "Epoch 10/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0711 - f1: 0.9736 - accuracy: 0.9736 - val_loss: 1.5387 - val_f1: 0.7513 - val_accuracy: 0.7508\n",
      "Epoch 11/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0816 - f1: 0.9722 - accuracy: 0.9722 - val_loss: 1.4840 - val_f1: 0.7397 - val_accuracy: 0.7396\n",
      "Epoch 12/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0736 - f1: 0.9725 - accuracy: 0.9725 - val_loss: 1.3674 - val_f1: 0.7426 - val_accuracy: 0.7425\n",
      "Epoch 13/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0732 - f1: 0.9738 - accuracy: 0.9738 - val_loss: 1.4642 - val_f1: 0.7569 - val_accuracy: 0.7564\n",
      "Epoch 14/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0697 - f1: 0.9739 - accuracy: 0.9738 - val_loss: 1.3981 - val_f1: 0.7596 - val_accuracy: 0.7576\n",
      "Epoch 15/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0912 - f1: 0.9685 - accuracy: 0.9683 - val_loss: 1.5316 - val_f1: 0.7339 - val_accuracy: 0.7335\n",
      "705/705 [==============================] - 3s 5ms/step - loss: 1.5316 - f1: 0.7339 - accuracy: 0.7335\n",
      "====================\n",
      "this is my loss:1.5316128730773926\n",
      "this is my accuracy:0.7338550090789795\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-03 01:28:28,735] Trial 203 finished with value: 0.7334989309310913 and parameters: {'number_of_hidden_layers': 9, 'dr_rate': 0.032642182568550754, 'activation_type': 'tanh', 'num_hidden_units_1': 20, 'num_hidden_units_2': 15, 'num_hidden_units_3': 62, 'num_hidden_units_4': 67, 'num_hidden_units_5': 12, 'num_hidden_units_6': 9, 'num_hidden_units_7': 50, 'num_hidden_units_8': 78, 'num_hidden_units_9': 82}. Best is trial 41 with value: 0.7686746120452881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.1646254382716193 tanh\n",
      "Epoch 1/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.3373 - f1: 0.8910 - accuracy: 0.8955 - val_loss: 1.4999 - val_f1: 0.6863 - val_accuracy: 0.6860\n",
      "Epoch 2/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.2158 - f1: 0.9376 - accuracy: 0.9378 - val_loss: 1.3835 - val_f1: 0.7093 - val_accuracy: 0.7092\n",
      "Epoch 3/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.1800 - f1: 0.9469 - accuracy: 0.9472 - val_loss: 1.2936 - val_f1: 0.7241 - val_accuracy: 0.7235\n",
      "Epoch 4/15\n",
      "985/985 [==============================] - 9s 9ms/step - loss: 0.1470 - f1: 0.9576 - accuracy: 0.9578 - val_loss: 1.5135 - val_f1: 0.7266 - val_accuracy: 0.7258\n",
      "Epoch 5/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.1296 - f1: 0.9642 - accuracy: 0.9642 - val_loss: 1.4274 - val_f1: 0.7250 - val_accuracy: 0.7246\n",
      "Epoch 6/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1264 - f1: 0.9649 - accuracy: 0.9651 - val_loss: 1.5292 - val_f1: 0.7173 - val_accuracy: 0.7171\n",
      "Epoch 7/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.1331 - f1: 0.9606 - accuracy: 0.9609 - val_loss: 1.3549 - val_f1: 0.7410 - val_accuracy: 0.7410\n",
      "Epoch 8/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.1250 - f1: 0.9617 - accuracy: 0.9618 - val_loss: 1.4372 - val_f1: 0.7375 - val_accuracy: 0.7371\n",
      "Epoch 9/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1238 - f1: 0.9615 - accuracy: 0.9617 - val_loss: 1.3601 - val_f1: 0.7448 - val_accuracy: 0.7526\n",
      "Epoch 10/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.1201 - f1: 0.9616 - accuracy: 0.9614 - val_loss: 1.3983 - val_f1: 0.7302 - val_accuracy: 0.7303\n",
      "Epoch 11/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.1248 - f1: 0.9610 - accuracy: 0.9607 - val_loss: 1.3936 - val_f1: 0.7499 - val_accuracy: 0.7492\n",
      "Epoch 12/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.1250 - f1: 0.9615 - accuracy: 0.9614 - val_loss: 1.2979 - val_f1: 0.7473 - val_accuracy: 0.7421\n",
      "Epoch 13/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1255 - f1: 0.9609 - accuracy: 0.9609 - val_loss: 1.3366 - val_f1: 0.7486 - val_accuracy: 0.7433\n",
      "Epoch 14/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1185 - f1: 0.9616 - accuracy: 0.9616 - val_loss: 1.3708 - val_f1: 0.7445 - val_accuracy: 0.7535\n",
      "Epoch 15/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.1194 - f1: 0.9658 - accuracy: 0.9658 - val_loss: 1.2745 - val_f1: 0.7394 - val_accuracy: 0.7385\n",
      "705/705 [==============================] - 3s 4ms/step - loss: 1.2745 - f1: 0.7388 - accuracy: 0.7385\n",
      "====================\n",
      "this is my loss:1.2745413780212402\n",
      "this is my accuracy:0.7388160824775696\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-03 01:30:27,215] Trial 204 finished with value: 0.7385113835334778 and parameters: {'number_of_hidden_layers': 8, 'dr_rate': 0.1646254382716193, 'activation_type': 'tanh', 'num_hidden_units_1': 27, 'num_hidden_units_2': 11, 'num_hidden_units_3': 59, 'num_hidden_units_4': 64, 'num_hidden_units_5': 42, 'num_hidden_units_6': 11, 'num_hidden_units_7': 77, 'num_hidden_units_8': 75}. Best is trial 41 with value: 0.7686746120452881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.0942059599658536 tanh\n",
      "Epoch 1/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.2644 - f1: 0.9134 - accuracy: 0.9174 - val_loss: 1.4673 - val_f1: 0.7157 - val_accuracy: 0.7147\n",
      "Epoch 2/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.1599 - f1: 0.9483 - accuracy: 0.9483 - val_loss: 1.4527 - val_f1: 0.7294 - val_accuracy: 0.7290\n",
      "Epoch 3/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.1290 - f1: 0.9564 - accuracy: 0.9565 - val_loss: 1.4358 - val_f1: 0.7253 - val_accuracy: 0.7253\n",
      "Epoch 4/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1189 - f1: 0.9627 - accuracy: 0.9627 - val_loss: 1.4423 - val_f1: 0.7138 - val_accuracy: 0.7135\n",
      "Epoch 5/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.1159 - f1: 0.9645 - accuracy: 0.9643 - val_loss: 1.4558 - val_f1: 0.7164 - val_accuracy: 0.7144\n",
      "Epoch 6/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.1058 - f1: 0.9646 - accuracy: 0.9647 - val_loss: 1.3648 - val_f1: 0.7315 - val_accuracy: 0.7311\n",
      "Epoch 7/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.1012 - f1: 0.9667 - accuracy: 0.9668 - val_loss: 1.3961 - val_f1: 0.7320 - val_accuracy: 0.7317\n",
      "Epoch 8/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0925 - f1: 0.9686 - accuracy: 0.9685 - val_loss: 1.2814 - val_f1: 0.7554 - val_accuracy: 0.7543\n",
      "Epoch 9/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0930 - f1: 0.9671 - accuracy: 0.9671 - val_loss: 1.3964 - val_f1: 0.7510 - val_accuracy: 0.7500\n",
      "Epoch 10/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0941 - f1: 0.9681 - accuracy: 0.9681 - val_loss: 1.3527 - val_f1: 0.7435 - val_accuracy: 0.7429\n",
      "Epoch 11/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0920 - f1: 0.9694 - accuracy: 0.9694 - val_loss: 1.4178 - val_f1: 0.7196 - val_accuracy: 0.7191\n",
      "Epoch 12/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0938 - f1: 0.9686 - accuracy: 0.9687 - val_loss: 1.4544 - val_f1: 0.7290 - val_accuracy: 0.7285\n",
      "Epoch 13/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0871 - f1: 0.9697 - accuracy: 0.9696 - val_loss: 1.5152 - val_f1: 0.7268 - val_accuracy: 0.7267\n",
      "Epoch 14/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.0929 - f1: 0.9694 - accuracy: 0.9694 - val_loss: 1.4518 - val_f1: 0.7394 - val_accuracy: 0.7315\n",
      "Epoch 15/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0907 - f1: 0.9690 - accuracy: 0.9690 - val_loss: 1.4838 - val_f1: 0.7379 - val_accuracy: 0.7301\n",
      "705/705 [==============================] - 3s 5ms/step - loss: 1.4838 - f1: 0.7375 - accuracy: 0.7301\n",
      "====================\n",
      "this is my loss:1.4838354587554932\n",
      "this is my accuracy:0.737483561038971\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-03 01:32:24,600] Trial 205 finished with value: 0.7300834059715271 and parameters: {'number_of_hidden_layers': 8, 'dr_rate': 0.0942059599658536, 'activation_type': 'tanh', 'num_hidden_units_1': 24, 'num_hidden_units_2': 16, 'num_hidden_units_3': 53, 'num_hidden_units_4': 71, 'num_hidden_units_5': 30, 'num_hidden_units_6': 16, 'num_hidden_units_7': 67, 'num_hidden_units_8': 93}. Best is trial 41 with value: 0.7686746120452881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.0660467509193451 tanh\n",
      "Epoch 1/15\n",
      "985/985 [==============================] - 6s 7ms/step - loss: 0.2323 - f1: 0.9213 - accuracy: 0.9257 - val_loss: 1.3305 - val_f1: 0.7099 - val_accuracy: 0.7095\n",
      "Epoch 2/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1354 - f1: 0.9585 - accuracy: 0.9585 - val_loss: 1.3163 - val_f1: 0.7233 - val_accuracy: 0.7231\n",
      "Epoch 3/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1054 - f1: 0.9677 - accuracy: 0.9677 - val_loss: 1.3904 - val_f1: 0.7346 - val_accuracy: 0.7341\n",
      "Epoch 4/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0914 - f1: 0.9703 - accuracy: 0.9703 - val_loss: 1.4888 - val_f1: 0.7367 - val_accuracy: 0.7362\n",
      "Epoch 5/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0721 - f1: 0.9767 - accuracy: 0.9767 - val_loss: 1.5764 - val_f1: 0.7495 - val_accuracy: 0.7483\n",
      "Epoch 6/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0648 - f1: 0.9806 - accuracy: 0.9806 - val_loss: 1.6656 - val_f1: 0.7371 - val_accuracy: 0.7371\n",
      "Epoch 7/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0740 - f1: 0.9764 - accuracy: 0.9764 - val_loss: 1.6772 - val_f1: 0.7382 - val_accuracy: 0.7369\n",
      "Epoch 8/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0736 - f1: 0.9762 - accuracy: 0.9761 - val_loss: 1.5260 - val_f1: 0.7443 - val_accuracy: 0.7411\n",
      "Epoch 9/15\n",
      "985/985 [==============================] - 6s 7ms/step - loss: 0.0767 - f1: 0.9741 - accuracy: 0.9741 - val_loss: 1.5653 - val_f1: 0.7386 - val_accuracy: 0.7377\n",
      "Epoch 10/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0728 - f1: 0.9747 - accuracy: 0.9747 - val_loss: 1.5661 - val_f1: 0.7388 - val_accuracy: 0.7383\n",
      "Epoch 11/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0783 - f1: 0.9738 - accuracy: 0.9738 - val_loss: 1.3539 - val_f1: 0.7417 - val_accuracy: 0.7416\n",
      "Epoch 12/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0793 - f1: 0.9745 - accuracy: 0.9745 - val_loss: 1.6163 - val_f1: 0.7380 - val_accuracy: 0.7375\n",
      "Epoch 13/15\n",
      "985/985 [==============================] - 6s 7ms/step - loss: 0.0787 - f1: 0.9771 - accuracy: 0.9771 - val_loss: 1.5925 - val_f1: 0.7277 - val_accuracy: 0.7270\n",
      "Epoch 14/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0687 - f1: 0.9803 - accuracy: 0.9802 - val_loss: 1.4899 - val_f1: 0.7502 - val_accuracy: 0.7501\n",
      "Epoch 15/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0762 - f1: 0.9745 - accuracy: 0.9744 - val_loss: 1.5514 - val_f1: 0.7511 - val_accuracy: 0.7504\n",
      "705/705 [==============================] - 3s 4ms/step - loss: 1.5514 - f1: 0.7505 - accuracy: 0.7504\n",
      "====================\n",
      "this is my loss:1.5514171123504639\n",
      "this is my accuracy:0.7505310773849487\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-03 01:34:05,680] Trial 206 finished with value: 0.7503992319107056 and parameters: {'number_of_hidden_layers': 5, 'dr_rate': 0.0660467509193451, 'activation_type': 'tanh', 'num_hidden_units_1': 28, 'num_hidden_units_2': 8, 'num_hidden_units_3': 70, 'num_hidden_units_4': 69, 'num_hidden_units_5': 48}. Best is trial 41 with value: 0.7686746120452881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.018462746578715685 tanh\n",
      "Epoch 1/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.2309 - f1: 0.9179 - accuracy: 0.9278 - val_loss: 1.1406 - val_f1: 0.7473 - val_accuracy: 0.7492\n",
      "Epoch 2/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1006 - f1: 0.9665 - accuracy: 0.9667 - val_loss: 1.2898 - val_f1: 0.7484 - val_accuracy: 0.7476\n",
      "Epoch 3/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0887 - f1: 0.9674 - accuracy: 0.9673 - val_loss: 1.2786 - val_f1: 0.7338 - val_accuracy: 0.7333\n",
      "Epoch 4/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0808 - f1: 0.9714 - accuracy: 0.9714 - val_loss: 1.3360 - val_f1: 0.7510 - val_accuracy: 0.7505\n",
      "Epoch 5/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0796 - f1: 0.9706 - accuracy: 0.9706 - val_loss: 1.4348 - val_f1: 0.7486 - val_accuracy: 0.7476\n",
      "Epoch 6/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0757 - f1: 0.9721 - accuracy: 0.9720 - val_loss: 1.4388 - val_f1: 0.7605 - val_accuracy: 0.7599\n",
      "Epoch 7/15\n",
      "985/985 [==============================] - 6s 7ms/step - loss: 0.0733 - f1: 0.9730 - accuracy: 0.9729 - val_loss: 1.5693 - val_f1: 0.7410 - val_accuracy: 0.7395\n",
      "Epoch 8/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0693 - f1: 0.9747 - accuracy: 0.9746 - val_loss: 1.6140 - val_f1: 0.7467 - val_accuracy: 0.7456\n",
      "Epoch 9/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0685 - f1: 0.9740 - accuracy: 0.9740 - val_loss: 1.5065 - val_f1: 0.7494 - val_accuracy: 0.7487\n",
      "Epoch 10/15\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0688 - f1: 0.9730 - accuracy: 0.9731 - val_loss: 1.4962 - val_f1: 0.7481 - val_accuracy: 0.7470\n",
      "Epoch 11/15\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0673 - f1: 0.9745 - accuracy: 0.9745 - val_loss: 1.4113 - val_f1: 0.7491 - val_accuracy: 0.7484\n",
      "Epoch 12/15\n",
      "985/985 [==============================] - 13s 13ms/step - loss: 0.0702 - f1: 0.9717 - accuracy: 0.9717 - val_loss: 1.5173 - val_f1: 0.7527 - val_accuracy: 0.7518\n",
      "Epoch 13/15\n",
      "985/985 [==============================] - 13s 13ms/step - loss: 0.0659 - f1: 0.9724 - accuracy: 0.9723 - val_loss: 1.4664 - val_f1: 0.7609 - val_accuracy: 0.7526\n",
      "Epoch 14/15\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0658 - f1: 0.9746 - accuracy: 0.9745 - val_loss: 1.5383 - val_f1: 0.7359 - val_accuracy: 0.7351\n",
      "Epoch 15/15\n",
      "985/985 [==============================] - 11s 11ms/step - loss: 0.0692 - f1: 0.9727 - accuracy: 0.9728 - val_loss: 1.6062 - val_f1: 0.7379 - val_accuracy: 0.7372\n",
      "705/705 [==============================] - 5s 7ms/step - loss: 1.6062 - f1: 0.7373 - accuracy: 0.7372\n",
      "====================\n",
      "this is my loss:1.6061855554580688\n",
      "this is my accuracy:0.7373029589653015\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-03 01:36:32,756] Trial 207 finished with value: 0.7372249960899353 and parameters: {'number_of_hidden_layers': 6, 'dr_rate': 0.018462746578715685, 'activation_type': 'tanh', 'num_hidden_units_1': 26, 'num_hidden_units_2': 24, 'num_hidden_units_3': 63, 'num_hidden_units_4': 59, 'num_hidden_units_5': 14, 'num_hidden_units_6': 23}. Best is trial 41 with value: 0.7686746120452881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.04269502517665 relu\n",
      "Epoch 1/15\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 166.0815 - f1: 0.7889 - accuracy: 0.8069 - val_loss: 13.0834 - val_f1: 0.6790 - val_accuracy: 0.6812\n",
      "Epoch 2/15\n",
      "985/985 [==============================] - 11s 11ms/step - loss: 20.0851 - f1: 0.8829 - accuracy: 0.8866 - val_loss: 8.1150 - val_f1: 0.7306 - val_accuracy: 0.7300\n",
      "Epoch 3/15\n",
      "985/985 [==============================] - 11s 11ms/step - loss: 7.7648 - f1: 0.9241 - accuracy: 0.9244 - val_loss: 2.8666 - val_f1: 0.7326 - val_accuracy: 0.7327\n",
      "Epoch 4/15\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 2.7446 - f1: 0.9441 - accuracy: 0.9439 - val_loss: 1.2844 - val_f1: 0.7370 - val_accuracy: 0.7365\n",
      "Epoch 5/15\n",
      "985/985 [==============================] - 11s 11ms/step - loss: 2.6763 - f1: 0.9549 - accuracy: 0.9549 - val_loss: 1.2281 - val_f1: 0.7283 - val_accuracy: 0.7279\n",
      "Epoch 6/15\n",
      "985/985 [==============================] - 9s 9ms/step - loss: 0.2388 - f1: 0.9608 - accuracy: 0.9607 - val_loss: 1.2207 - val_f1: 0.7309 - val_accuracy: 0.7298\n",
      "Epoch 7/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.1705 - f1: 0.9636 - accuracy: 0.9634 - val_loss: 1.2321 - val_f1: 0.7358 - val_accuracy: 0.7354\n",
      "Epoch 8/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.2448 - f1: 0.9645 - accuracy: 0.9645 - val_loss: 1.2680 - val_f1: 0.7316 - val_accuracy: 0.7309\n",
      "Epoch 9/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.1521 - f1: 0.9670 - accuracy: 0.9670 - val_loss: 1.2585 - val_f1: 0.7345 - val_accuracy: 0.7334\n",
      "Epoch 10/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.2586 - f1: 0.9654 - accuracy: 0.9656 - val_loss: 1.3138 - val_f1: 0.7434 - val_accuracy: 0.7425\n",
      "Epoch 11/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.1404 - f1: 0.9674 - accuracy: 0.9675 - val_loss: 1.2775 - val_f1: 0.7422 - val_accuracy: 0.7416\n",
      "Epoch 12/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.1851 - f1: 0.9680 - accuracy: 0.9681 - val_loss: 1.4305 - val_f1: 0.7254 - val_accuracy: 0.7246\n",
      "Epoch 13/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.1259 - f1: 0.9675 - accuracy: 0.9676 - val_loss: 1.3793 - val_f1: 0.7370 - val_accuracy: 0.7291\n",
      "Epoch 14/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.4737 - f1: 0.9696 - accuracy: 0.9695 - val_loss: 1.2679 - val_f1: 0.7424 - val_accuracy: 0.7414\n",
      "Epoch 15/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.1174 - f1: 0.9729 - accuracy: 0.9727 - val_loss: 1.2421 - val_f1: 0.7524 - val_accuracy: 0.7511\n",
      "705/705 [==============================] - 3s 4ms/step - loss: 1.2421 - f1: 0.7519 - accuracy: 0.7511\n",
      "====================\n",
      "this is my loss:1.2421414852142334\n",
      "this is my accuracy:0.7518510818481445\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-03 01:38:52,778] Trial 208 finished with value: 0.7511089444160461 and parameters: {'number_of_hidden_layers': 9, 'dr_rate': 0.04269502517665, 'activation_type': 'relu', 'num_hidden_units_1': 23, 'num_hidden_units_2': 12, 'num_hidden_units_3': 47, 'num_hidden_units_4': 62, 'num_hidden_units_5': 33, 'num_hidden_units_6': 74, 'num_hidden_units_7': 57, 'num_hidden_units_8': 85, 'num_hidden_units_9': 60}. Best is trial 41 with value: 0.7686746120452881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.4711830549088746 tanh\n",
      "Epoch 1/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.7778 - f1: 0.6916 - accuracy: 0.7241 - val_loss: 1.5565 - val_f1: 0.6240 - val_accuracy: 0.6236\n",
      "Epoch 2/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.5370 - f1: 0.8432 - accuracy: 0.8443 - val_loss: 1.4968 - val_f1: 0.6332 - val_accuracy: 0.6325\n",
      "Epoch 3/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.5044 - f1: 0.8476 - accuracy: 0.8483 - val_loss: 1.4454 - val_f1: 0.6383 - val_accuracy: 0.6382\n",
      "Epoch 4/15\n",
      "985/985 [==============================] - 8s 8ms/step - loss: 0.4825 - f1: 0.8511 - accuracy: 0.8524 - val_loss: 1.3944 - val_f1: 0.6431 - val_accuracy: 0.6421\n",
      "Epoch 5/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.4712 - f1: 0.8522 - accuracy: 0.8535 - val_loss: 1.3948 - val_f1: 0.6432 - val_accuracy: 0.6415\n",
      "Epoch 6/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.4648 - f1: 0.8530 - accuracy: 0.8545 - val_loss: 1.3883 - val_f1: 0.6498 - val_accuracy: 0.6492\n",
      "Epoch 7/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.4597 - f1: 0.8545 - accuracy: 0.8556 - val_loss: 1.3728 - val_f1: 0.6445 - val_accuracy: 0.6441\n",
      "Epoch 8/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.4579 - f1: 0.8547 - accuracy: 0.8556 - val_loss: 1.3719 - val_f1: 0.6461 - val_accuracy: 0.6457\n",
      "Epoch 9/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.4502 - f1: 0.8564 - accuracy: 0.8581 - val_loss: 1.3676 - val_f1: 0.6521 - val_accuracy: 0.6512\n",
      "Epoch 10/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.4450 - f1: 0.8574 - accuracy: 0.8590 - val_loss: 1.3115 - val_f1: 0.6530 - val_accuracy: 0.6521\n",
      "Epoch 11/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.4396 - f1: 0.8594 - accuracy: 0.8606 - val_loss: 1.3629 - val_f1: 0.6538 - val_accuracy: 0.6533\n",
      "Epoch 12/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.4354 - f1: 0.8586 - accuracy: 0.8596 - val_loss: 1.3733 - val_f1: 0.6529 - val_accuracy: 0.6525\n",
      "Epoch 13/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.4386 - f1: 0.8594 - accuracy: 0.8606 - val_loss: 1.3605 - val_f1: 0.6487 - val_accuracy: 0.6483\n",
      "Epoch 14/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.4334 - f1: 0.8596 - accuracy: 0.8613 - val_loss: 1.3527 - val_f1: 0.6518 - val_accuracy: 0.6513\n",
      "Epoch 15/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.4269 - f1: 0.8590 - accuracy: 0.8601 - val_loss: 1.2798 - val_f1: 0.6621 - val_accuracy: 0.6619\n",
      "705/705 [==============================] - 3s 4ms/step - loss: 1.2798 - f1: 0.6618 - accuracy: 0.6619\n",
      "====================\n",
      "this is my loss:1.2797602415084839\n",
      "this is my accuracy:0.6617618799209595\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-03 01:40:46,390] Trial 209 finished with value: 0.6618612408638 and parameters: {'number_of_hidden_layers': 8, 'dr_rate': 0.4711830549088746, 'activation_type': 'tanh', 'num_hidden_units_1': 19, 'num_hidden_units_2': 4, 'num_hidden_units_3': 57, 'num_hidden_units_4': 65, 'num_hidden_units_5': 19, 'num_hidden_units_6': 58, 'num_hidden_units_7': 19, 'num_hidden_units_8': 57}. Best is trial 41 with value: 0.7686746120452881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.11241511685555448 tanh\n",
      "Epoch 1/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.2310 - f1: 0.9209 - accuracy: 0.9261 - val_loss: 1.4096 - val_f1: 0.7151 - val_accuracy: 0.7146\n",
      "Epoch 2/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1207 - f1: 0.9627 - accuracy: 0.9628 - val_loss: 1.3844 - val_f1: 0.7228 - val_accuracy: 0.7225\n",
      "Epoch 3/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1002 - f1: 0.9688 - accuracy: 0.9688 - val_loss: 1.4635 - val_f1: 0.7168 - val_accuracy: 0.7302\n",
      "Epoch 4/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0927 - f1: 0.9700 - accuracy: 0.9700 - val_loss: 1.4894 - val_f1: 0.7468 - val_accuracy: 0.7457\n",
      "Epoch 5/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0941 - f1: 0.9679 - accuracy: 0.9679 - val_loss: 1.4716 - val_f1: 0.7537 - val_accuracy: 0.7531\n",
      "Epoch 6/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0938 - f1: 0.9671 - accuracy: 0.9670 - val_loss: 1.4440 - val_f1: 0.7421 - val_accuracy: 0.7414\n",
      "Epoch 7/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1022 - f1: 0.9645 - accuracy: 0.9644 - val_loss: 1.5317 - val_f1: 0.7367 - val_accuracy: 0.7360\n",
      "Epoch 8/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0903 - f1: 0.9663 - accuracy: 0.9662 - val_loss: 1.4259 - val_f1: 0.7350 - val_accuracy: 0.7343\n",
      "Epoch 9/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0915 - f1: 0.9681 - accuracy: 0.9682 - val_loss: 1.5062 - val_f1: 0.7405 - val_accuracy: 0.7410\n",
      "Epoch 10/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0852 - f1: 0.9700 - accuracy: 0.9700 - val_loss: 1.4069 - val_f1: 0.7559 - val_accuracy: 0.7549\n",
      "Epoch 11/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0824 - f1: 0.9694 - accuracy: 0.9694 - val_loss: 1.4471 - val_f1: 0.7527 - val_accuracy: 0.7524\n",
      "Epoch 12/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0728 - f1: 0.9761 - accuracy: 0.9761 - val_loss: 1.4451 - val_f1: 0.7410 - val_accuracy: 0.7403\n",
      "Epoch 13/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0769 - f1: 0.9726 - accuracy: 0.9726 - val_loss: 1.5651 - val_f1: 0.7497 - val_accuracy: 0.7487\n",
      "Epoch 14/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0892 - f1: 0.9669 - accuracy: 0.9669 - val_loss: 1.4767 - val_f1: 0.7429 - val_accuracy: 0.7423\n",
      "Epoch 15/15\n",
      "985/985 [==============================] - 6s 6ms/step - loss: 0.0825 - f1: 0.9710 - accuracy: 0.9709 - val_loss: 1.4206 - val_f1: 0.7608 - val_accuracy: 0.7599\n",
      "705/705 [==============================] - 3s 4ms/step - loss: 1.4206 - f1: 0.7600 - accuracy: 0.7599\n",
      "====================\n",
      "this is my loss:1.4205650091171265\n",
      "this is my accuracy:0.7600280046463013\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-03 01:42:30,561] Trial 210 finished with value: 0.7598917484283447 and parameters: {'number_of_hidden_layers': 6, 'dr_rate': 0.11241511685555448, 'activation_type': 'tanh', 'num_hidden_units_1': 30, 'num_hidden_units_2': 81, 'num_hidden_units_3': 50, 'num_hidden_units_4': 75, 'num_hidden_units_5': 16, 'num_hidden_units_6': 66}. Best is trial 41 with value: 0.7686746120452881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.1349009888933395 tanh\n",
      "Epoch 1/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.2378 - f1: 0.9213 - accuracy: 0.9261 - val_loss: 1.4082 - val_f1: 0.7293 - val_accuracy: 0.7284\n",
      "Epoch 2/15\n",
      "985/985 [==============================] - 6s 7ms/step - loss: 0.1228 - f1: 0.9589 - accuracy: 0.9591 - val_loss: 1.4584 - val_f1: 0.7312 - val_accuracy: 0.7311\n",
      "Epoch 3/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1091 - f1: 0.9638 - accuracy: 0.9638 - val_loss: 1.5377 - val_f1: 0.7384 - val_accuracy: 0.7355\n",
      "Epoch 4/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0990 - f1: 0.9664 - accuracy: 0.9664 - val_loss: 1.5918 - val_f1: 0.7529 - val_accuracy: 0.7521\n",
      "Epoch 5/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0979 - f1: 0.9668 - accuracy: 0.9667 - val_loss: 1.6318 - val_f1: 0.7453 - val_accuracy: 0.7449\n",
      "Epoch 6/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0970 - f1: 0.9670 - accuracy: 0.9669 - val_loss: 1.4135 - val_f1: 0.7514 - val_accuracy: 0.7507\n",
      "Epoch 7/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0836 - f1: 0.9705 - accuracy: 0.9705 - val_loss: 1.4926 - val_f1: 0.7490 - val_accuracy: 0.7479\n",
      "Epoch 8/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0834 - f1: 0.9707 - accuracy: 0.9707 - val_loss: 1.6112 - val_f1: 0.7667 - val_accuracy: 0.7583\n",
      "Epoch 9/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0859 - f1: 0.9686 - accuracy: 0.9685 - val_loss: 1.4887 - val_f1: 0.7541 - val_accuracy: 0.7534\n",
      "Epoch 10/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0820 - f1: 0.9704 - accuracy: 0.9704 - val_loss: 1.5403 - val_f1: 0.7505 - val_accuracy: 0.7496\n",
      "Epoch 11/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0749 - f1: 0.9739 - accuracy: 0.9738 - val_loss: 1.6166 - val_f1: 0.7481 - val_accuracy: 0.7472\n",
      "Epoch 12/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0796 - f1: 0.9719 - accuracy: 0.9720 - val_loss: 1.5890 - val_f1: 0.7425 - val_accuracy: 0.7424\n",
      "Epoch 13/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0759 - f1: 0.9740 - accuracy: 0.9740 - val_loss: 1.5533 - val_f1: 0.7574 - val_accuracy: 0.7564\n",
      "Epoch 14/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0749 - f1: 0.9734 - accuracy: 0.9734 - val_loss: 1.5070 - val_f1: 0.7749 - val_accuracy: 0.7739\n",
      "Epoch 15/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0818 - f1: 0.9712 - accuracy: 0.9711 - val_loss: 1.5773 - val_f1: 0.7340 - val_accuracy: 0.7334\n",
      "705/705 [==============================] - 3s 4ms/step - loss: 1.5773 - f1: 0.7333 - accuracy: 0.7334\n",
      "====================\n",
      "this is my loss:1.5772992372512817\n",
      "this is my accuracy:0.7333487272262573\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-03 01:44:16,086] Trial 211 finished with value: 0.7334102392196655 and parameters: {'number_of_hidden_layers': 6, 'dr_rate': 0.1349009888933395, 'activation_type': 'tanh', 'num_hidden_units_1': 30, 'num_hidden_units_2': 81, 'num_hidden_units_3': 51, 'num_hidden_units_4': 74, 'num_hidden_units_5': 17, 'num_hidden_units_6': 65}. Best is trial 41 with value: 0.7686746120452881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.1136652994209555 tanh\n",
      "Epoch 1/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.2427 - f1: 0.9200 - accuracy: 0.9256 - val_loss: 1.2767 - val_f1: 0.7366 - val_accuracy: 0.7259\n",
      "Epoch 2/15\n",
      "985/985 [==============================] - 7s 8ms/step - loss: 0.1337 - f1: 0.9596 - accuracy: 0.9597 - val_loss: 1.5137 - val_f1: 0.7146 - val_accuracy: 0.7138\n",
      "Epoch 3/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1127 - f1: 0.9615 - accuracy: 0.9617 - val_loss: 1.4730 - val_f1: 0.7265 - val_accuracy: 0.7257\n",
      "Epoch 4/15\n",
      "985/985 [==============================] - 6s 7ms/step - loss: 0.1045 - f1: 0.9626 - accuracy: 0.9627 - val_loss: 1.5940 - val_f1: 0.7357 - val_accuracy: 0.7351\n",
      "Epoch 5/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0916 - f1: 0.9709 - accuracy: 0.9708 - val_loss: 1.6204 - val_f1: 0.7386 - val_accuracy: 0.7379\n",
      "Epoch 6/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0971 - f1: 0.9670 - accuracy: 0.9670 - val_loss: 1.5070 - val_f1: 0.7288 - val_accuracy: 0.7288\n",
      "Epoch 7/15\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.0994 - f1: 0.9643 - accuracy: 0.9643 - val_loss: 1.7374 - val_f1: 0.7385 - val_accuracy: 0.7376\n",
      "Epoch 8/15\n",
      "Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "# Optuna citation - https://optuna.org/#code_examples\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, BatchNormalization\n",
    "import optuna\n",
    "\n",
    "# Defining an objective function which needs to be maximized.\n",
    "def objective(trial):\n",
    "\n",
    "    # Hard coded values (not changing with respect to code)\n",
    "    batch_size=128\n",
    "    epochs=15\n",
    "    batch_normalization_after_layer=2\n",
    "\n",
    "    # define search space; number of hidden layers, dropout rate, activation function.\n",
    "    num_hidden_layers=trial.suggest_int(\"number_of_hidden_layers\",1,10)\n",
    "    drop_out_rate=trial.suggest_uniform(\"dr_rate\",0,1)\n",
    "    activation_list=[\"tanh\",\"sigmoid\",\"swish\",\"relu\"]\n",
    "    activation_type=trial.suggest_categorical(\"activation_type\",activation_list)\n",
    "    print(num_hidden_layers,drop_out_rate,activation_type)\n",
    "\n",
    "    # Initializing the model\n",
    "    model=tf.keras.Sequential()\n",
    "\n",
    "      # Here, 1 is the hidden layer. So, we are starting from the 1st hidden layer\n",
    "      # Because 0th layer is the input of dimensions i.e. number of columns\n",
    "    for layer in range(1,num_hidden_layers+1):\n",
    "        # We are going to add number of hidden units.\n",
    "        num_hidden_units=trial.suggest_int(\"num_hidden_units_{}\".format(layer),2,96)\n",
    "        if(layer==1):\n",
    "          model.add(Dense(num_hidden_units,activation=activation_type,input_shape=(input_dimensions,)))\n",
    "        else:\n",
    "          model.add(Dense(num_hidden_units,activation=activation_type))\n",
    "        # Adding dropout for randomly discarding neurons\n",
    "        model.add(Dropout(drop_out_rate))\n",
    "        # Batch normalization after 3rd layer\n",
    "        if(layer%batch_normalization_after_layer+1==0):\n",
    "          model.add(BatchNormalization())\n",
    "\n",
    "    # For out put we use SOFTMAX\n",
    "    # Softmax by default which provides probabilities\n",
    "    # Softmax function inbuilt in tensorflow\n",
    "    model.add(Dense(output_dimension,activation=\"softmax\"))\n",
    "    \n",
    "    # Compilation of the model\n",
    "    # Choosing optimiser \"adam\" whcih is better than \"Gradient Descent\".\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=[f1,\"accuracy\"])\n",
    "    \n",
    "    # Fitting the model\n",
    "    # Returning from F1-Score\n",
    "    model.fit(X_tr,y_tr,batch_size=batch_size,epochs=epochs,validation_data=(X_test,y_test))\n",
    "    results=model.evaluate(X_test,y_test)\n",
    "    print(\"=\"*20)\n",
    "    print(\"this is my loss:{}\".format(results[0]))\n",
    "    print(\"this is my accuracy:{}\".format(results[1]))\n",
    "    print(\"=\"*20)\n",
    "\n",
    "    return results[2]\n",
    "\n",
    "# Creating a study object and optimizing the objective function.\n",
    "study = optuna.create_study(direction='maximize',study_name=\"NN_tuning\",storage=\"sqlite:///nn_net.db\",load_if_exists=True)\n",
    "# n_trials means number of trials\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "Vxb5qZgLwhp7",
    "outputId": "67aa3d01-aaca-486e-e3f2-569884d1535b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-03 03:45:42,163] Using an existing study with name 'NN_tuning' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params {'activation_type': 'tanh', 'dr_rate': 0.03587723263680438, 'num_hidden_units_1': 29, 'num_hidden_units_2': 49, 'num_hidden_units_3': 62, 'num_hidden_units_4': 77, 'num_hidden_units_5': 20, 'num_hidden_units_6': 70, 'number_of_hidden_layers': 6}\n",
      "f1-- 0.7686746120452881\n",
      "best trial-- FrozenTrial(number=41, value=0.7686746120452881, datetime_start=datetime.datetime(2020, 8, 2, 18, 35, 9, 922652), datetime_complete=datetime.datetime(2020, 8, 2, 18, 36, 15, 386685), params={'activation_type': 'tanh', 'dr_rate': 0.03587723263680438, 'num_hidden_units_1': 29, 'num_hidden_units_2': 49, 'num_hidden_units_3': 62, 'num_hidden_units_4': 77, 'num_hidden_units_5': 20, 'num_hidden_units_6': 70, 'number_of_hidden_layers': 6}, distributions={'activation_type': CategoricalDistribution(choices=('tanh', 'sigmoid', 'swish', 'relu')), 'dr_rate': UniformDistribution(high=1, low=0), 'num_hidden_units_1': IntUniformDistribution(high=96, low=2, step=1), 'num_hidden_units_2': IntUniformDistribution(high=96, low=2, step=1), 'num_hidden_units_3': IntUniformDistribution(high=96, low=2, step=1), 'num_hidden_units_4': IntUniformDistribution(high=96, low=2, step=1), 'num_hidden_units_5': IntUniformDistribution(high=96, low=2, step=1), 'num_hidden_units_6': IntUniformDistribution(high=96, low=2, step=1), 'number_of_hidden_layers': IntUniformDistribution(high=10, low=1, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=42, state=TrialState.COMPLETE)\n"
     ]
    }
   ],
   "source": [
    "# Again loading the object from the nn_net file and updating it again.\n",
    "study = optuna.create_study(direction='maximize',study_name=\"NN_tuning\",storage=\"sqlite:///nn_net.db\",load_if_exists=True)\n",
    "import pandas as pd\n",
    "print(\"best_params\",study.best_params)\n",
    "print(\"f1--\",study.best_value)\n",
    "print(\"best trial--\",study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "U0E721qdOyxp",
    "outputId": "63f3440e-09f6-44a8-cba1-046e74c96487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'function'>\n",
      "Epoch 1/20\n",
      "985/985 [==============================] - 9s 9ms/step - loss: 0.2296 - f1: 0.9267 - accuracy: 0.9278 - val_loss: 1.4415 - val_f1: 0.7294 - val_accuracy: 0.7288\n",
      "Epoch 2/20\n",
      "985/985 [==============================] - 9s 9ms/step - loss: 0.1159 - f1: 0.9614 - accuracy: 0.9614 - val_loss: 1.4269 - val_f1: 0.7480 - val_accuracy: 0.7478\n",
      "Epoch 3/20\n",
      "985/985 [==============================] - 9s 9ms/step - loss: 0.0986 - f1: 0.9651 - accuracy: 0.9651 - val_loss: 1.4673 - val_f1: 0.7418 - val_accuracy: 0.7411\n",
      "Epoch 4/20\n",
      "985/985 [==============================] - 8s 9ms/step - loss: 0.0898 - f1: 0.9660 - accuracy: 0.9661 - val_loss: 1.2996 - val_f1: 0.7591 - val_accuracy: 0.7585\n",
      "Epoch 5/20\n",
      "517/985 [==============>...............] - ETA: 3s - loss: 0.0837 - f1: 0.9706 - accuracy: 0.9705"
     ]
    }
   ],
   "source": [
    "# Recreating the ANN to check is everything alright\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, BatchNormalization\n",
    "import tensorflow as tf\n",
    "\n",
    "# Best parameters we obtained from optuna\n",
    "# Now, running again to make sure is everything fine\n",
    "drop_out_rate=0.0358\n",
    "batch_size=128\n",
    "epochs=20\n",
    "\n",
    "print(type(f1))\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\")\n",
    "# Here, 29, 49, 62, 77 are number of hidden neurons\n",
    "model=tf.keras.Sequential()\n",
    "model.add(Dense(29,activation=\"tanh\",input_shape=(input_dimensions,)))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "model.add(Dense(49,activation=\"tanh\"))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "model.add(Dense(62,activation=\"tanh\"))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(77,activation=\"tanh\"))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "model.add(Dense(20,activation=\"tanh\"))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "model.add(Dense(70,activation=\"tanh\"))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "model.add(BatchNormalization())\n",
    "# For generating output we select 5 nodes as we have 5 classes.\n",
    "model.add(Dense(5,activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=[f1,\"accuracy\"])\n",
    "\n",
    "model.fit(X_tr,y_tr,batch_size=batch_size,epochs=epochs,validation_data=(X_test,y_test),callbacks=[callback])\n",
    "results=model.evaluate(X_test,y_test)\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"this is my loss:{}\".format(results[0]))\n",
    "print(\"this is my accuracy:{}\".format(results[1]))\n",
    "print(\"this is my f1:{}\".format(results[2]))\n",
    "print(\"=\"*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mLqSVu1Iw6I"
   },
   "outputs": [],
   "source": [
    "# Saving the model in the google drive\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DRhQ9LER7KO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ANN.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "common-cpu.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
